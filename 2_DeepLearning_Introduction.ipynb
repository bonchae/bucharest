{"cells":[{"cell_type":"markdown","source":["# Neural Network: The Origin of Deep Learning"],"metadata":{"id":"UBtmMPId5Am2"},"id":"UBtmMPId5Am2"},{"cell_type":"markdown","source":["<img src=\"https://towardsdatascience.com/wp-content/uploads/2021/12/1hkYlTODpjJgo32DoCOWN5w.png\">\n","\n"],"metadata":{"id":"FDcOWftZ5GMN"},"id":"FDcOWftZ5GMN"},{"cell_type":"markdown","source":["## Consider this sample data"],"metadata":{"id":"FPVcsHKC7v_S"},"id":"FPVcsHKC7v_S"},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import pandas as pd\n","\n","# Sample churn dataset\n","url = 'https://raw.githubusercontent.com/bonchae/data/refs/heads/master/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n","df = pd.read_csv(url)\n","df.head()"],"metadata":{"id":"OB3T8l_97_ne"},"id":"OB3T8l_97_ne","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Telco Customer Churn Dataset: Feature Definitions\n","\n","| Feature Name        | Description                                                                 |\n","|---------------------|-----------------------------------------------------------------------------|\n","| `customerID`        | Unique ID assigned to each customer (dropped in modeling)                  |\n","| `gender`            | Customer’s gender: `Male`, `Female`                                        |\n","| `SeniorCitizen`     | Indicates if the customer is a senior (1) or not (0)                       |\n","| `Partner`           | Whether the customer has a partner (`Yes`/`No`)                            |\n","| `Dependents`        | Whether the customer has dependents (`Yes`/`No`)                           |\n","| `tenure`            | Number of months the customer has been with the company                    |\n","| `PhoneService`      | Whether the customer has phone service (`Yes`/`No`)                        |\n","| `MultipleLines`     | If customer has multiple phone lines                                       |\n","| `InternetService`   | Type of internet: `DSL`, `Fiber optic`, or `No`                            |\n","| `OnlineSecurity`    | Whether the customer has online security add-on                            |\n","| `OnlineBackup`      | Whether the customer has online backup service                             |\n","| `DeviceProtection`  | Whether the customer has device protection plan                            |\n","| `TechSupport`       | Whether the customer has technical support access                          |\n","| `StreamingTV`       | Whether the customer has streaming TV service                              |\n","| `StreamingMovies`   | Whether the customer has streaming movies access                           |\n","| `Contract`          | Type of contract: `Month-to-month`, `One year`, `Two year`                |\n","| `PaperlessBilling`  | Whether billing is paperless (`Yes`/`No`)                                  |\n","| `PaymentMethod`     | Method of payment: `Electronic check`, `Mailed check`, etc.                |\n","| `MonthlyCharges`    | Amount charged to the customer monthly (in dollars)                        |\n","| `TotalCharges`      | Total amount charged over the customer’s lifetime                          |\n","| `Churn`             | Target variable: whether the customer left in the last month (`Yes`/`No`)  |\n","\n","**Note:** After preprocessing, categorical variables are converted into dummy variables, and `Churn_Yes` becomes the binary target (1 = churned, 0 = stayed).\n"],"metadata":{"id":"3i0LwAu_71jH"},"id":"3i0LwAu_71jH"},{"cell_type":"markdown","source":["<center><img src=\"https://miro.medium.com/v2/format:webp/1*Ne7jPeR6Vrl1f9d7pLLG8Q.jpeg\"></center>\n","\n","[Source](https://medium.com/@b.terryjack/introduction-to-deep-learning-feed-forward-neural-networks-ffnns-a-k-a-c688d83a309d)"],"metadata":{"id":"79TRLnaZjvDl"},"id":"79TRLnaZjvDl"},{"cell_type":"markdown","source":["Input Layer\n","- This is where data enters the model\n","- Each feature (column) in your data (e.g., **tenure, contract type, monthly charges**) is one neuron\n","- It passes the raw information to the next layer — no learning happens here\n","\n","Hidden Layers\n","- These are the “thinking” layers of the model\n","- They learn patterns in the data by **transforming inputs with weights** and activations\n","- The more hidden layers or neurons, the more **complex patterns** the model can learn\n","\n","Output Layer\n","- This layer gives the **final prediction**\n","- Example: 1 neuron with sigmoid activation → **churn probability**\n","- In multi-class problems: multiple neurons with softmax\n","\n","For structured business data (like churn), 1–2 hidden layers are usually enough.\n","More layers don’t always help and can even hurt if the data is small or noisy."],"metadata":{"id":"xL0-OV1F7zN9"},"id":"xL0-OV1F7zN9"},{"cell_type":"markdown","source":["# What is “Deep”?\n"],"metadata":{"id":"08mC8JeL5eZ6"},"id":"08mC8JeL5eZ6"},{"cell_type":"markdown","source":["“Deep” just means **many layers** of neurons. Each layer **extracts increasingly complex features** from data (e.g., images, texts).\n","\n","- **Early layers (Convolution + ReLU) → Low-level features**  \n","  Detect **edges**, **colors**, **textures**, **blobs**.\n","\n","- **Middle layers (More Convolution + Pooling) → Mid-level patterns**  \n","  Recognize **corners**, **shapes**, **simple parts of objects**.\n","\n","- **Deeper layers (Final Convolutional Stages) → High-level representations**  \n","  Detect **eyes**, **faces**, **objects**, **categories**.\n","\n","> This hierarchical feature extraction is exactly what makes CNNs so powerful for image-related tasks."],"metadata":{"id":"asTOfrtJ5hZC"},"id":"asTOfrtJ5hZC"},{"cell_type":"markdown","source":["<img src=\"https://i0.wp.com/developersbreach.com/wp-content/uploads/2020/08/cnn_banner.png?fit=1400%2C658&ssl=1\">"],"metadata":{"id":"KNnmdaXI9-tT"},"id":"KNnmdaXI9-tT"},{"cell_type":"markdown","id":"4da730f9-6f75-47d6-8a84-92698a659538","metadata":{"id":"4da730f9-6f75-47d6-8a84-92698a659538"},"source":["<h2 style=\"text-align: center;\">Deep Learning Algorithm Hierarchy with Business Applications</h2>\n","\n","<table border=\"1\" cellspacing=\"0\" cellpadding=\"8\" style=\"margin: auto; text-align: left; font-family: sans-serif;\">\n","  <tr style=\"background-color: #8cbeb2; text-align: center;\">\n","    <th><strong>Type</strong></th>\n","    <th><strong>Business Applications</strong></th>\n","    <th><strong>Real-World Examples</strong></th>\n","  </tr>\n","\n","  <tr>\n","    <td><strong>CNNs</strong><br><small>Convolutional Neural Networks</small></td>\n","    <td>\n","      <ul>\n","        <li><strong>Image classification (e.g., product recognition)</strong></li>\n","        <li>Medical image diagnostics</li>\n","        <li>Quality control in manufacturing</li>\n","        <li>Facial recognition in security</li>\n","      </ul>\n","    </td>\n","    <td>\n","      <ul>\n","        <li>Google Lens</li>\n","        <li>Apple Face ID</li>\n","        <li>Siemens AI Medical Imaging</li>\n","        <li>Amazon Go Surveillance</li>\n","      </ul>\n","    </td>\n","  </tr>\n","\n","  <tr>\n","    <td><strong>RNNs</strong><br><small>Recurrent Neural Networks</small></td>\n","    <td>\n","      <ul>\n","        <li>Stock and sales forecasting</li>\n","        <li>Customer churn prediction</li>\n","        <li>Speech-to-text transcription</li>\n","        <li>Chatbot conversation modeling</li>\n","      </ul>\n","    </td>\n","    <td>\n","      <ul>\n","        <li>Google Voice</li>\n","        <li>Nuance Dragon Speech</li>\n","        <li>Apple Siri (early versions)</li>\n","        <li>Amazon Forecast</li>\n","      </ul>\n","    </td>\n","  </tr>\n","\n","  <tr>\n","    <td><strong>GANs</strong><br><small>Generative Adversarial Networks</small></td>\n","    <td>\n","      <ul>\n","        <li>Synthetic data generation</li>\n","        <li>Product design and prototyping</li>\n","        <li>AI-generated media and marketing visuals</li>\n","        <li>Art and creative content generation</li>\n","      </ul>\n","    </td>\n","    <td>\n","      <ul>\n","        <li><strong>DALL·E</strong> (OpenAI)</li>\n","        <li>Midjourney</li>\n","        <li>StyleGAN (NVIDIA)</li>\n","        <li>Runway ML</li>\n","      </ul>\n","    </td>\n","  </tr>\n","\n","  <tr>\n","    <td><strong>Transformers</strong><br><small>LLMs / Attention-Based Models</small></td>\n","    <td>\n","      <ul>\n","        <li>Customer support chatbots</li>\n","        <li>Sentiment analysis and social listening</li>\n","        <li>Text summarization and document search</li>\n","        <li>Personalized recommendations and Q&A</li>\n","      </ul>\n","    </td>\n","    <td>\n","      <ul>\n","        <li><strong>ChatGPT</strong> (OpenAI)</li>\n","        <li>Google Bard</li>\n","        <li>GitHub Copilot</li>\n","        <li>Google Translate</li>\n","      </ul>\n","    </td>\n","  </tr>\n","\n","  <tr>\n","    <td><strong>DRL</strong><br><small>Deep Reinforcement Learning</small></td>\n","    <td>\n","      <ul>\n","        <li>Autonomous vehicles and robotics</li>\n","        <li>Dynamic pricing systems</li>\n","        <li>Supply chain and inventory optimization</li>\n","        <li>Simulated training environments</li>\n","      </ul>\n","    </td>\n","    <td>\n","      <ul>\n","        <li>Waymo Self-Driving Cars</li>\n","        <li>DeepMind AlphaGo</li>\n","        <li>OpenAI Five (Dota 2)</li>\n","        <li>Amazon Warehouse Optimization</li>\n","      </ul>\n","    </td>\n","  </tr>\n","</table>\n"]},{"cell_type":"markdown","id":"lKUTE49dV45D","metadata":{"id":"lKUTE49dV45D"},"source":["# Popularity Ranking of DL Architectures (as of 2025)\n","\n","| Rank | Architecture     | Popularity               | Primary Use Cases                                        |\n","|------|------------------|--------------------------|----------------------------------------------------------|\n","| 1️⃣   | Transformers      | ⭐⭐⭐⭐⭐ *(most popular)*    | LLMs, NLP, vision, audio, multimodal                     |\n","| 2️⃣   | CNNs              | ⭐⭐⭐⭐                     | Image classification, object detection, vision tasks     |\n","| 3️⃣   | GANs              | ⭐⭐⭐                      | Image generation, style transfer, data augmentation      |\n","| 4️⃣   | RNNs / LSTMs      | ⭐⭐                       | Legacy NLP, time series prediction, audio modeling       |\n"]},{"cell_type":"markdown","source":["# Two Broad Ways to Use Deep Learning Models\n","\n"],"metadata":{"id":"knY33LDfcVp9"},"id":"knY33LDfcVp9"},{"cell_type":"markdown","source":["## 1. Using Pre-trained Models\n","\n","You take a model that has already been trained on a large dataset (like **ImageNet**, **COCO**, or a large text corpus).\n","\n","You can:\n","- Use it **as-is** for inference\n","- **Fine-tune** it on your own smaller dataset\n","- **Pros**: Faster, requires less data and compute, great for transfer learning\n","\n","\n","\n"],"metadata":{"id":"hi2vd1HTiMNV"},"id":"hi2vd1HTiMNV"},{"cell_type":"markdown","source":["## 2. Training Models from Scratch\n","\n","You define your model architecture and train it from the beginning using your dataset.\n","\n","- **Pros**: Complete control, better for novel or domain-specific problems  \n","- **Cons**: Requires large datasets, longer training time, and more compute resources"],"metadata":{"id":"xNmjuxnsiQ2b"},"id":"xNmjuxnsiQ2b"},{"cell_type":"markdown","source":["# A Quick Demo"],"metadata":{"id":"iMuiZWeylcZs"},"id":"iMuiZWeylcZs"},{"cell_type":"markdown","source":["## Emotion Detection using Pre-trained Models\n","Use case: Go beyond \"positive/negative\" — detect emotions like joy, anger, sadness"],"metadata":{"id":"u6P6JW-aicdY"},"id":"u6P6JW-aicdY"},{"cell_type":"markdown","source":["<img src=\"https://webflow-amber-prod.gumlet.io/620e4101b2ce12a1a6bff0e8/66ab6846124b51c486c24b3e_640f1bb03074900cbf0f28f3_What-are-the-Ivy-League-schools.webp\" width=700>"],"metadata":{"id":"NomWUOVSipKn"},"id":"NomWUOVSipKn"},{"cell_type":"markdown","source":["**\"I can't believe I got in! I'm so happy and feel very grateful.\"**"],"metadata":{"id":"O8WespZzi1CH"},"id":"O8WespZzi1CH"},{"cell_type":"code","source":["from transformers import pipeline\n","\n","emotion = pipeline(\"text-classification\",\n","                   model=\"j-hartmann/emotion-english-distilroberta-base\",\n","                   top_k=None)\n","\n","results = emotion(\"I can't believe I got in! I'm so happy and feel very grateful.\")\n","\n","for row in results:\n","    for item in row:\n","        print(f\"{item['label']:<10} -> {item['score']:.4f}\")"],"metadata":{"id":"3RI4Iz2FieQJ"},"id":"3RI4Iz2FieQJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_classifier = pipeline(\n","    \"text-classification\",\n","    model=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n","    top_k=None\n",")\n","\n","text = \"I can't believe I got in! I'm so happy and feel very grateful.\"\n","results = emotion_classifier(text)\n","\n","for row in results:\n","    for item in row:\n","        print(f\"{item['label']:<10} -> {item['score']:.4f}\")"],"metadata":{"id":"O7Y8BRk8kvtY"},"id":"O7Y8BRk8kvtY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Try a different sentence\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"OThcXKB60QDC"},"id":"OThcXKB60QDC","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training Emotion Detection Model from Scratch"],"metadata":{"id":"eD11zNd3mgxX"},"id":"eD11zNd3mgxX"},{"cell_type":"code","source":["# import packages\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder"],"metadata":{"id":"Bl9-tW2Ymu6m"},"id":"Bl9-tW2Ymu6m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tiny dataset for demonstration\n","data = {\n","    \"text\": [\n","        \"I'm so happy and grateful\",\n","        \"This is terrible. I'm really mad\",\n","        \"I feel scared and anxious\",\n","        \"What a surprise! I didn’t expect that\",\n","        \"I'm feeling so loved and supported\",\n","        \"This makes me really sad\"\n","    ],\n","    \"emotion\": [\n","        \"joy\",\n","        \"anger\",\n","        \"fear\",\n","        \"surprise\",\n","        \"love\",\n","        \"sadness\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n","df"],"metadata":{"id":"dfSprV84lxxg"},"id":"dfSprV84lxxg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(df['text'])\n","X = tokenizer.texts_to_sequences(df['text'])\n","X = pad_sequences(X, padding='post')\n","\n","# Encode labels\n","le = LabelEncoder()\n","y = le.fit_transform(df['emotion'])\n","\n","# Check vocab size\n","vocab_size = len(tokenizer.word_index) + 1"],"metadata":{"id":"kYbscXKDlx0c"},"id":"kYbscXKDlx0c","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The model below performs much better than traditional sentiment analysis since it uses ```Embedding``` that understand word sequence pattern. This is more than word matching. For example,\n","\n","```\"I’m so ____ and ____\"``` → joy\n","\n","```\"This is ____\"``` → anger or sadness"],"metadata":{"id":"27c8dXZW0pLc"},"id":"27c8dXZW0pLc"},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=16, input_length=X.shape[1]),\n","    LSTM(16),\n","    Dense(6, activation='softmax')  # 6 emotions\n","])\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n"],"metadata":{"id":"SkpQtmZ-lx3J"},"id":"SkpQtmZ-lx3J","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X, y, epochs=30, verbose=1)"],"metadata":{"id":"Yu7DB-8Hlx6U"},"id":"Yu7DB-8Hlx6U","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Your test sentence\n","test_text = [\"I can't believe I got in! I'm so happy and feel very grateful.\"]\n","\n","# Preprocess the test input\n","test_seq = tokenizer.texts_to_sequences(test_text)\n","test_pad = pad_sequences(test_seq, maxlen=X.shape[1], padding='post')\n","\n","# Predict emotion\n","pred = model.predict(test_pad)\n","emotion_label = le.inverse_transform([pred.argmax()])[0]\n","\n","# Print Output\n","print(f\"Text: {test_text[0]}\")\n","print(f\"Predicted Emotion: {emotion_label}\")\n"],"metadata":{"id":"8AhhqErllx9v"},"id":"8AhhqErllx9v","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Try a different sentence\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"lOLbKS1izkD1"},"id":"lOLbKS1izkD1","execution_count":null,"outputs":[]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}